version: "3"
services:
  prediction_api:
    build: .  
    container_name: "inference_container_compose"
    ports:
      - "8000:8000"